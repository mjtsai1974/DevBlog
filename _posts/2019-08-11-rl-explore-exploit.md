---
layout: post
title: Explore versus Exploit
---

## Prologue To <font color="Red">Explore</font> versus <font color="Red">Exploit</font>
<p class="message">
Some reference of articles states that exploration is the topic that separates reinforcement learning from other kinds of machine learning.  Exploration is part of fundamental trade off of reinforcement learning.
</p>

### Begin from K-Armed Bandits
><font color="DeepSkyBlue">[1]</font>
><font color="OrangeRed">K-armed bandits</font>  
>Supposed we are given K-armed bandits, where $K$=$7$ in below exhibition.  <font color="RosyBrown">The bandit has no state transition, all about stochasticity</font>, you pull it, you either get a jackpot, or you don't get a jackpot.  
![]({{ site.github.repo }}{{ site.baseurl }}/images/pic/2019-08-11-rl-explore-exploit-k-armed-bandits.png "k-armed bandits")
>
><font color="DeepSkyBlue">[2]</font>
><font color="RoyalBlue">Which one you will pull?</font>  
>In this example, suppose each machine will have different paypffs.  The question is <font color="RoyalBlue">which bandit will you pull?</font>  
>&#10112;the one that has the best chance of winning the jackpot, giving you money.  
>&#10113;the point is that we don't know the payoffs are, hard to decide which bandit to choose.  
>&#10114;if we know the payoffs, just do the $max_{arm}Bandit(arm)$ could we get the answer.  
>
><font color="DeepSkyBlue">[3]</font>
><font color="DeepPink">we have to explore</font>  
>Suppose each bandit has some probability of paying off a one, some probability of paying off nothing, saying that zero.  But, we don't know what it is at first.  
>
>If we pull bandit a, and it doesn't pay off, does it mean that bandit a is not the best one?  <font color="RosyBrown">No</font>, we don't know what anything else is.  
>
>One arm pull just give us some information, but not an awful lot.  We have to combine information across a whole lot of pulls to start to evaluate what the best bandit is.  
>
>So, <font color="DeepPink">we have to explore</font>!!  
>
><font color="DeepSkyBlue">[4]</font>
><font color="OrangeRed">Illustration</font>  
>Suppose each of these bandits has been pulled multiple times and come out the number of times that it pays off 1, with the fomer in the denominator, the later in the nominator, given in below exhibition.  
![]({{ site.github.repo }}{{ site.baseurl }}/images/pic/2019-08-11-rl-explore-exploit-k-armed-bandits-ex.png "ex")
>In between a and e, it looks as if that bandit e is better than bandit a, since the same 10 pulls of bandit, e has payed 2 times, while a just 1 time.  
>
>Next to examine in between a and d, the bandit d gave the pay off only after 5 pulls, it might also be plausible if we prefer to bandit d rather than a.  
>
>By the given data, we have 2 concerns:  
>&#10112;which bandit is the <font color="OrangeRed">highest expected</font> pay off?  
>&#10113;which are we <font color="OrangeRed">most confident</font> in?  
>
>For &#10112;, the bandits d,e,f,g just play to a tie, since  
>$\frac {1}{5}\cdot 1$+$\frac {4}{5}\cdot 0$,$\frac {2}{10}\cdot 1$+$\frac {8}{10}\cdot 0$,$\frac {4}{20}\cdot 1$+$\frac {16}{20}\cdot 0$, $\frac {8}{40}\cdot 1$+$\frac {32}{40}\cdot 0$, are the expected pay off for bandit d,e,f,g respectively.  They are all the same higher than the rest.  
>
>For &#10113;, as to the confidence level, if you choose g, it might be a good answer, but <font color="RosyBrown">not the good reason</font>.  <font color="DeepPink">When it comes to expectation, the confidence level is monotonically increasing function of the numbers of sample.</font>  so, <font color="DeepPink">whichever has the biggest pulling numbers should be the most confident</font>, because it has most samples.  We finally compare c and g, and choose g.  

### Confidence-Based Exploration
><font color="DeepSkyBlue">[1]</font>
><font color="OrangeRed">Something else in stochasticity</font>  
>Given 2 bandits a and b, you make 1 pull of a and get 0 pay off, whereas, you make 2 pulls of b and get 1 pay off.  Do you think the best thing at this point is to <font color="OrangeRed">always</font> pick up a, <font color="OrangeRed">always</font> pick up b, or <font color="DeepPink">something else</font>?  
>
>Trivially, <font color="DeepPink">something else</font>.  
>
>First, let's calculate out the probability for:  
>&#10112;always a to get 0 pay off  
>$\frac {1}{C_{1}^{3}}\cdot 1$=$\frac {1}{3}$  
>Since there exists 1 pull of bandit a out of the 3 pulls, and it indeed come out with 0 pay off.  
>
>&#10113;always b to get 1 pay off  
>$\frac {1}{C_{2}^{3}}\cdot 2$=$\frac {2}{3}$  
>We treat 3 pulls as distinct computation unit, by given, there exists 2 pulls of bandit b and come out with 1 pay off.  Totally 2 out of 3 pulls, we prefer all bandit b, where each pull is not replacable, and the 1 pay off might be appeared in the 1st or 2nd pull, that's why we multiply by 2 at the end.  
>
>Suppose you choose bandit b by intuition, you are right $\frac {2}{3}$ of the time, but with $\frac {1}{3}$ of chance you make mistake.  That's why we end up with <font color="DeepPink">something else</font>.  
>
><font color="DeepSkyBlue">[2]</font>
><font color="RoyalBlue">What is something else?</font>  
>If we run an arbitrary number of pulls, what is something else?  I think, we might just evaluate which bandit to pull after some time, or infinite amount of time later.  Then, I might know the true expected value for pulling bandit a or b, so I know which to choose.  
>
>It refers to the thing I'd like to do to get me <font color="DeepPink">more confidence in my expectation</font>, and more number of pulls explicitly.  

### Addendum
>&#10112;[Exploring Exploration, Charles IsBell, Michael Littman, Reinforcement Learning By Georgia Tech(CS8803)](https://classroom.udacity.com/courses/ud600/lessons/4402978778/concepts/44548888230923)  

<!-- Γ -->
<!-- \Omega -->
<!-- \cap intersection -->
<!-- \cup union -->
<!-- \frac{\Gamma(k + n)}{\Gamma(n)} \frac{1}{r^k}  -->
<!-- \mbox{\large$\vert$}\nolimits_0^\infty -->
<!-- \vert_0^\infty -->
<!-- \vert_{0.5}^{\infty} -->
<!-- &prime; ′ -->
<!-- &Prime; ″ -->
<!-- $E\lbrack X\rbrack$ -->
<!-- \overline{X_n} -->
<!-- \underset{Succss}P -->
<!-- \frac{{\overline {X_n}}-\mu}{S/\sqrt n} -->
<!-- \lim_{t\rightarrow\infty} -->
<!-- \int_{0}^{a}\lambda\cdot e^{-\lambda\cdot t}\operatorname dt -->
<!-- \Leftrightarrow -->
<!-- \prod_{v\in V} -->
<!-- \subset -->
<!-- \subseteq -->
<!-- \varnothing -->
<!-- \perp -->
<!-- \overset\triangle= -->
<!-- \left|X\right| -->
<!-- \xrightarrow{r_t} -->
<!-- \left\|?\right\| => ||?||-->
<!-- \left|?\right| => |?|-->
<!-- \lbrack BQ\rbrack => [BQ] -->
<!-- \subset -->
<!-- \subseteq -->

<!-- Notes -->
<!-- <font color="OrangeRed">items, verb, to make it the focus, mathematic expression</font> -->
<!-- <font color="Red">KKT</font> -->
<!-- <font color="Red">SMO heuristics</font> -->
<!-- <font color="Red">F</font> distribution -->
<!-- <font color="Red">t</font> distribution -->
<!-- <font color="DeepSkyBlue">suggested item, soft item</font> -->
<!-- <font color="RoyalBlue">old alpha, quiz, example</font> -->
<!-- <font color="Green">new alpha</font> -->

<!-- <font color="#C20000">conclusion, finding</font> -->
<!-- <font color="DeepPink">positive conclusion, finding</font> -->
<!-- <font color="RosyBrown">negative conclusion, finding</font> -->

<!-- <font color="#00ADAD">policy</font> -->
<!-- <font color="#6100A8">full observable</font> -->
<!-- <font color="#FFAC12">partial observable</font> -->
<!-- <font color="#EB00EB">stochastic</font> -->
<!-- <font color="#8400E6">state transition</font> -->
<!-- <font color="#D600D6">discount factor gamma $\gamma$</font> -->
<!-- <font color="#D600D6">$V(S)$</font> -->
<!-- <font color="#9300FF">immediate reward R(S)</font> -->

<!-- ### <font color="RoyalBlue">Example</font>: Illustration By Rainy And Sunny Days In One Week -->
<!-- <font color="RoyalBlue">[Question]</font> -->
<!-- <font color="DeepSkyBlue">[Answer]</font> -->

<!-- <font color="Brown">Notes::mjtsai1974</font> -->

<!-- 
[1]Given the vehicles pass through a highway toll station is $6$ per minute, what is the probability that no cars within $30$ seconds?
><font color="DeepSkyBlue">[1]</font>
><font color="OrangeRed">Given the vehicles pass through a highway toll station is $6$ per minute, what is the probability that no cars within $30$ seconds?</font>  
-->

<!--
><font color="DeepSkyBlue">[Notes]</font>
><font color="OrangeRed">Why at this moment, the Poisson and exponential probability come out with different result?</font>  
-->

<!-- https://www.medcalc.org/manual/gamma_distribution_functions.php -->
<!-- https://www.statlect.com/probability-distributions/student-t-distribution#hid5 -->
<!-- http://www.wiris.com/editor/demo/en/ -->