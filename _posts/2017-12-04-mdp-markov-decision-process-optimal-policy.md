---
layout: post
title: Markov Decision Process To Seek The Optimal Policy
---

## Markov Decision Process To Seek The Optimal Policy

<p class="message">
We could treat MDP as the way the world works, then, <font color="#00ADAD">policy</font> would be the way the agent works.  If you take an MDP with a <font color="#00ADAD">policy</font> containing all of the actions are chosen and it would now just become a Markov Chain without action to be taken.  
Nevertheless, <font color="#C20000">a policy aims at mapping each distinct state to an optimal action maximizing the value of the state over the horizon of some magnitude or even infinity</font>.  Given a policy, it's easy to evaluate the expected value from each possible starting state by executing it. 
</p>



<!-- Notes -->
<!-- <font color="#00ADAD">policy</font> -->
<!-- <font color="#6100A8">full observable</font> -->
<!-- <font color="#FFAC12">partial observable</font> -->
<!-- <font color="#EB00EB">stochastic</font> -->
<!-- <font color="#8400E6">state transition</font> -->
<!-- <font color="DeepSkyBlue">optimal action</font> -->
<!-- <font color="#C20000">positive conclusion, finding</font> -->
<!-- <font color="green">negative conclusion, finding</font> -->